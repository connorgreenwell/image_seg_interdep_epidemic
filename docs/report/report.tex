\documentclass[twocolumn]{article}

\usepackage{color}
\usepackage[margin=1in,bottom=1.5in]{geometry}

\usepackage{graphicx}
\usepackage{subcaption}

% Comment out second line to disable.
% Thanks: https://gist.github.com/orbekk/1298622
\newcommand{\todo}[1]{}
\renewcommand{\todo}[1]{{\color{red} TODO: {#1}}}

\newcommand{\secref}[1]{Section~\ref{sec:#1}}
\newcommand{\seclab}[1]{\label{sec:#1}}
\newcommand{\figref}[1]{Figure~\ref{fig:#1}}
\newcommand{\figlab}[1]{\label{fig:#1}}
\newcommand{\tblref}[1]{Table~\ref{tbl:#1}}
\newcommand{\tbllab}[1]{\label{tbl:#1}}

\title{Modeling Image Segmentation as Epidemic Spread in an Interdependent Network}
\author{
  Connor Greenwell, Emory Hufbauer\\
  Computer Science Dept. \\
  University of Kentucky
}
\date{}

\begin{document}

\maketitle

\begin{abstract}
In this document we propose formulating the problem of image segmentation as
simulating the propagation of information/ownership through an interdependent
network where the first layer is a lattice representation of an input image and
the second layer is a (planar) overlay graph where each node has weighted edges
to pixels in the lattice. We will design and evaluate a number of propagation
models, primarily based on pixel/region similarity metrics. Finally we will
compare our method against classical and current state-of-the-art methods for
image segmentation on a variety of segmentation benchmark datasets. 
\end{abstract}

\section{Introduction}

``Instance segmentation is an important and popular topic in computer vision
\cite{newell2017associative, li2017fully, ren2017end}. Current state of the art
uses recurrent neural networks to segment an image into its consituent object
parts.  However occlusion is not handled well (is this actually true?). We
propose a method based on the endemic spread of information through an
interdependent network.'' 

\todo{some light background on image segmentation.}

\todo{some light background on interdependent networks. Why is this problem formulation better?}

We will first create an interdependent network model of an image. The
weights of edges between adjacent pixels in the lattice will represent
their degree of similarity to each other. The weights of edges between
nodes in the overlay graph will represent their overlap and estimated
potential to belong to the same object. The weights of edges between the
overlay and lattice will represent ownership of pixels by superpixels.
We will then perform a simultaneous, competitive propagation of multiple
phenomena through this network using a variety of models, with the
ultimate goal of developing a propagation model with property that,
after propagation has completed, the regions of the lattice affected by
each phenomena correspond well to the segments of the image.

The following paper is layed out as follows: In \secref{related} we survey the
current state of the art in image segmentation, as well as methods related to
ours. In \secref{approach} we describe our method in detail. In \secref{eval} we
describe the metrics by which we judge our methods and those we compare against.
In \secref{data} we describe the benchmark datasets against which we compare.
Finally, in \secref{results} we describe our resulting performance and
evaluation.

\section{Related Work}\seclab{related}

\todo{endemic spread in interdpenedent networks}

\todo{image segmentation: classic, modern, and weird methods}
\cite{pei2014saliency} use a Markov-Random-Field on precomputed super pixels to
perform image segmentation.  \cite{newell2017associative,li2017fully,ren2017end}
present a variety of neural network based approached to instance segmentation on
natural images.

\section{Approach}\seclab{approach}

First we encode an input image as a lattice graph of pixels. A random, planar
overlay graph is created and edges linked between each node and every pixel in
the image. The overlay graph has a low number of nodes, representing a prior on
the maximum number of objects that can possibly exist in a photograph. 

We will first create an interdependent network model of an image. The weights of
edges between adjacent pixels in the lattice will represent their degree of
similarity to each other. The weights of edges between nodes in the overlay
graph will represent their overlap and estimated potential to belong to the same
object. The weights of edges between the overlay and lattice will represent
ownership of pixels by superpixels.

We will then perform a simultaneous, competitive propagation of multiple
phenomena through this network using a variety of models, with the ultimate goal
of developing a propagation model with property that, after propagation has
completed, the regions of the lattice affected by each phenomena correspond well
to the segments of the image.

\todo{more complete description of planned experiments}

\subsection{Baseline}

A naive baseline method has been developed for us to compare our actual method
against. It is based on using DBSCAN \cite{ester1996density} to cluster and
merge superpixels produced by SLIC \cite{achanta2010slic}.

\begin{figure}

\centering
\includegraphics[width=\linewidth]{figs/searched.png}
\caption{Results from a baseline segmentation approach based on similariity
clustering of SLIC image superpixel segmentation.}
\figlab{baseline}

\end{figure}

\subsection{Image Network Extraction}

\begin{figure*}
\centering

\includegraphics[width=0.3\linewidth]{figs/input.png}
\includegraphics[width=0.3\linewidth]{figs/alpha.png}
\includegraphics[width=0.3\linewidth]{figs/beta.png}

\caption{
(left) A sample image from our dataset.
(middle) The inverse square of the difference between every pair of pixels in
the image. 
(right) Transformation of the color space to the median centroid of the image's
profile, projected onto the surface of a sphere in color space, points on the
surface of which represent unique, continuous, colors. The cosine of the angular
distance between each pair of pixels on the sphere.
(middle), and (right) are used to determine epidemic spread probabilities
between pixels in our approach.
}
\figlab{alpha_beta}
\end{figure*}

As a preprocessing step we extract two meaningful metrics from the pixels of an
input image and use them to define similarity scores between adjacent pixels.
\todo{maybe emory can ellaborate on this here}
The first is extracting value information from the image.
The approach takes the inverse square of the difference between every pair of
pixels in the image. 

The other method is extracting the hue data. This complements the value method
nicely.  First, we transform the color space to the median centroid of the
image's profile. We then compute the norm of each pixel in the image,
post-transform.  Next, we take the dot product of every pair of pixels, and
finally normalize against each via the norms recorded before.  Intuitively, it's
transforming the (0,0,0)->(1,1,1) cube of RGB color space to a hollow sphere
centered at the origin, points on the surface of which represent unique,
continuous, colors. We then output the cosine of the angular distance between
each pair of pixels on the sphere as a 4D structure like above.

The result of each approach is a four-dimensional array or "image of
images", which we visualize in \figref{alpha_beta}.

\begin{figure}
  \centering
  \includegraphics[width=\linewidth]{figs/ab_graphs.png}

  \caption{
    The original overlay graphs on a sample image. In each, lighter colors represent higher scores; best viewed in color.
    (left) alpha scores, based on color intensity. (right) beta scores, based on hue difference.
  }
  \figlab{ab_graph}

\end{figure}

\begin{figure}
  \centering

  \begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figs/single_source.png}
    \caption{Probability distribution over superpixels.}
  \end{subfigure}
  \begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figs/many_sources.png}
    \caption{Binary masks for various source regions.}
  \end{subfigure}
  \begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figs/aggregate.png}
    \caption{Aggregate of many binary masks. \todo{This is REALLY bad. I must be doing something wrong\ldots}}
  \end{subfigure}

  \caption{
    Overview of our method: First, a \todo{blarg}
  }
  \figlab{process}

\end{figure}

\section{Evaluation}\seclab{eval}

The goal of this project is mostly to explore the space and point to future
research possibilities. Although the results will be compared with those of
existing algorithms, they are not expected to be competitive with the state of
the art. To that end we will evaluate our performance on a variety of classic
image segmentation benchmark datasets, including PASCAL VOC and MS-COCO, as well
as compare our results against existing state-of-the-art segmentation methods. 

\todo{describe metrics here, probably need to restate the formula from Hebert's paper}

A number of evaluation metrics have been explored for performance on the task of
image segmentation. We have chosen the Adjusted Rand Score from
\cite{unnikrishnan2005measure}  Some other metrics to consider are Mutual
Information, FMI, and Homogeneity scores. These may be included in the final
paper if they tell an interesting story but our primary focus will be on
evluating against Hebert's ARS score.

\subsection{Datasets}\seclab{data}

\todo{we dont need all 4, trim down a bit probably}

\paragraph{PASCAL VOC} \todo{describe} \cite{Everingham10}.

\paragraph{Cityscapes Dataset} \todo{describe} \cite{cordts2016cityscapes}.

\paragraph{KITTI} \todo{describe} \cite{geiger2012we}

\paragraph{MS COCO} \todo{describe} \cite{lin2014microsoft}.

\section{Results}\seclab{results}

\begin{figure}
  \centering

  \includegraphics[width=\linewidth]{figs/bars.png}

  \caption{Comparison of Adjusted Rand Score on 100 images from the training set. Having more area to the right of the graph
indicates a higher proportion of high quality seqmentations. In this case, this indicates that our method is worse than our
defined baseline.
  }
  \figlab{bars}

\end{figure}

\begin{figure}
  \centering

  \begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figs/only_alpha.png}
    \caption{Sample segmentation using only the alpha scores.}
  \end{subfigure}
  \begin{subfigure}{\linewidth}
    \includegraphics[width=\linewidth]{figs/only_beta.png}
    \caption{Sample segmentation using only the beta scores.}
  \end{subfigure}

  \caption{
    \todo{foobar}
  }
  \figlab{ab_only}

\end{figure}

\todo{This section should be a boat load of tables and plots. Hopefully we look good in some of them}

\todo{
Mechanisms for performing hyperparameter optimization have been developed and tested on the naive baseline. This will be
necessary because our final method will likely have a number of tunable hyperparameters and it will be useful to automatically
find the optimal settings for our task.
}

\section{Conclusion}

\todo{restate what we did in more detail than we do in the intro}

\todo{future work}

\bibliographystyle{plain}
\bibliography{refs} 

\end{document}
