{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'dynSIS' from '/mounts/u-amo-d0/ugrad/connor/docs/homework/cs687/project/src/notebooks/dynSIS.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "import skimage.io as skio\n",
    "import skimage.util as sku\n",
    "import skimage.segmentation as seg\n",
    "from skimage.future import graph\n",
    "import skimage.filters as skf\n",
    "import skimage.color as skc\n",
    "\n",
    "from sklearn.neighbors import LocalOutlierFactor as LOF\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import networkx as nx\n",
    "import dynSIS\n",
    "import importlib\n",
    "importlib.reload(dynSIS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hufbauer_alpha(image, labels, connectivity=2, fudge=1e-8):\n",
    "    rag = graph.RAG(labels, connectivity=connectivity)\n",
    "\n",
    "    for n in rag:\n",
    "        rag.node[n].update({'labels': [n],\n",
    "                            'pixel count': 0,\n",
    "                            'total color': np.array([0, 0, 0],\n",
    "                                                    dtype=np.double)})\n",
    "\n",
    "    for index in np.ndindex(labels.shape):\n",
    "        current = labels[index]\n",
    "        rag.node[current]['pixel count'] += 1\n",
    "        rag.node[current]['total color'] += image[index]\n",
    "\n",
    "    for n in rag:\n",
    "        rag.node[n]['mean color'] = (rag.node[n]['total color'] /\n",
    "                                     rag.node[n]['pixel count'])\n",
    "        rag.node[n]['alpha'] = np.sum(rag.node[n]['mean color'] ** 2)\n",
    "\n",
    "    for x, y, d in rag.edges(data=True):\n",
    "        # TODO: might be wrong, check later\n",
    "        #d['weight'] = 1 / (fudge + (rag.node[x]['alpha'] - rag.node[y]['alpha']) ** 2)\n",
    "        d['weight'] = -((rag.node[x]['alpha'] - rag.node[y]['alpha']) ** 2.)\n",
    "        #d['weight'] = np.log((rag.node[x]['alpha'] - rag.node[y]['alpha']) ** 2.)\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hufbauer_beta(image, labels, connectivity=2):\n",
    "    image = skc.rgb2lab(image)[:, :, [1,2]]\n",
    "    rag = graph.RAG(labels, connectivity=connectivity)\n",
    "\n",
    "    for n in rag:\n",
    "        rag.node[n].update({'labels': [n],\n",
    "                            'pixel count': 0,\n",
    "                            'total hue': np.array([0, 0],\n",
    "                                                    dtype=np.double)})\n",
    "\n",
    "    for index in np.ndindex(labels.shape):\n",
    "        current = labels[index]\n",
    "        rag.node[current]['pixel count'] += 1\n",
    "        rag.node[current]['total hue'] += image[index]\n",
    "\n",
    "    for n in rag:\n",
    "        rag.node[n]['mean hue'] = (rag.node[n]['total hue'] /\n",
    "                                     rag.node[n]['pixel count'])\n",
    "\n",
    "    for x, y, d in rag.edges(data=True):\n",
    "        # TODO: might be wrong, check later\n",
    "        diff = 1 / (1 + (rag.node[x]['mean hue'] - rag.node[y]['mean hue']) ** 2)\n",
    "        diff = np.linalg.norm(diff)\n",
    "        d['weight'] = diff\n",
    "\n",
    "    return rag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_graph(g):\n",
    "    values = []\n",
    "    for _, _, d in g.edges(data=True):\n",
    "        values.append(d[\"weight\"])\n",
    "    values = np.sort(values)\n",
    "    \n",
    "    # outlier smoothing\n",
    "    outliers = LOF().fit_predict(values[:, None])\n",
    "    values =  values[outliers > 0]\n",
    "    min_val, max_val = values.min(), values.max() - values.min()\n",
    "    \n",
    "    for _, _, d in g.edges(data=True):\n",
    "        weight = d[\"weight\"]\n",
    "        \n",
    "        if weight > max_val: \n",
    "            weight = max_val\n",
    "        if weight < min_val:\n",
    "            weight = min_val\n",
    "        weight = (weight - min_val) / max_val\n",
    "        \n",
    "        d[\"weight\"] = weight\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_to_horizon(adj, N):\n",
    "    adj = np.matrix(adj)\n",
    "    for n in range(1, N+1):\n",
    "        yield adj ** n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_adj(img, sps):\n",
    "    num_sps = sps.max() + 1\n",
    "    \n",
    "    rag_a = normalize_graph(hufbauer_alpha(img, sps))\n",
    "    rag_b = normalize_graph(hufbauer_beta(img, sps))\n",
    "    \n",
    "    adj_a = nx.adjacency_matrix(rag_a).todense()\n",
    "    adj_b = nx.adjacency_matrix(rag_b).todense()\n",
    "\n",
    "    adj = np.c_[\n",
    "        np.r_[\n",
    "            adj_a, \n",
    "            np.diag(np.ones(num_sps)) * 0.1,\n",
    "        ],\n",
    "        np.r_[\n",
    "            np.diag(np.ones(num_sps)) * 0.1,\n",
    "            adj_b,\n",
    "        ],\n",
    "    ]\n",
    "    adj[np.diag_indices_from(adj)] += 1\n",
    "    \n",
    "    return adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segment_proposals_markov(adj, horizon):\n",
    "    num_sps = adj.shape[0] // 2\n",
    "    starts = np.c_[\"c\", np.diag(np.ones(num_sps)), np.diag(np.ones(num_sps))]\n",
    "    reached = starts * adj**horizon\n",
    "\n",
    "    reached = np.array(reached)\n",
    "    reached -= reached.min()\n",
    "    reached /= reached.max()\n",
    "    \n",
    "    return reached.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_proposals(proposals, sps, thresh):\n",
    "    masks = (proposals[sps] > thresh).astype(int)\n",
    "    \n",
    "    base = np.zeros_like(masks[:,:,0])\n",
    "    for mask in np.rollaxis(masks, 2):\n",
    "        base = seg.join_segmentations(base, mask)\n",
    "    return base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_method(img, horizon, merge_thresh):\n",
    "    sps = seg.slic(img, slic_zero=True)\n",
    "    adj = build_adj(img, sps)\n",
    "    proposals = segment_proposals_markov(adj, horizon)\n",
    "    segmentation = merge_proposals(proposals, sps, merge_thresh)\n",
    "    return segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import dataset\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building dataset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:20<00:00,  2.48it/s]\n",
      "24it [02:27,  6.14s/it]"
     ]
    }
   ],
   "source": [
    "print(\"building dataset...\")\n",
    "imgs, anno = dataset.make_dataset(limit=50)\n",
    "all_sps = [\n",
    "    seg.slic(img, slic_zero=True)\n",
    "    for img in tqdm.tqdm(imgs)\n",
    "]\n",
    "all_adj = [\n",
    "    build_adj(img, sps)\n",
    "    for img, sps in tqdm.tqdm(zip(imgs, all_sps))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#transmission_range = np.linspace(0., 1., 5, endpoint=True)\n",
    "horizon_range = np.arange(20, 100, 5)\n",
    "thresh_range = np.linspace(0.1, 0.9, 8, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_props = [\n",
    "    [\n",
    "        segment_proposals_markov(adj, horizon)\n",
    "        for adj, sps in zip(all_adj, all_sps)\n",
    "    ]\n",
    "    for horizon in tqdm.tqdm(horizon_range)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = [\n",
    "    np.mean([\n",
    "        adjusted_rand_score(\n",
    "            ann.flat,\n",
    "            merge_proposals(\n",
    "                prop,\n",
    "                sps, \n",
    "                thresh).flat)\n",
    "        for prop, sps, ann in zip(props, all_sps, anno)\n",
    "    ])\n",
    "    for props, thresh in tqdm.tqdm(it.product(all_props, thresh_range))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params = list(it.product(horizon_range, thresh_range))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(means), len(all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(zip(means, all_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict as ddict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon_ars, thresh_ars = ddict(list), ddict(list)\n",
    "for (horizon, thresh), ars in zip(all_params, means):\n",
    "    horizon_ars[horizon].append(horizon)    \n",
    "    thresh_ars[thresh].append(ars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(\n",
    "    horizon_ars.values(), \n",
    "    labels=horizon_ars.keys(), \n",
    "    vert=False);\n",
    "plt.xlabel(\"Adjusted Rand Score\")\n",
    "plt.ylabel(\"Epidemic Run Time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.boxplot(\n",
    "    thresh_ars.values(), \n",
    "    labels=[\"{:.02f}\".format(thresh) for thresh in thresh_ars.keys()], \n",
    "    vert=False);\n",
    "plt.xlabel(\"Adjusted Rand Score\")\n",
    "plt.ylabel(\"Mask Probability Threshold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params[np.argmax(means)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
